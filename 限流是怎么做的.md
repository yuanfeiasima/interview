# 一、全链路限流架构

我们的限流是分层设计的，从接入层到数据层都有限流措施，形成多道防线。

用户请求  
↓  
[接入层限流] - Nginx  
↓  
[网关层限流] - API Gateway  
↓  
[应用层限流] - Sentinel  
↓  
[缓存层限流] - Redis连接池  
↓  
[数据层限流] - DB连接池 + 慢查询熔断

---

# 二、各层限流的具体实现

## 1. 接入层限流（Nginx）

目的： 防止恶意流量和异常流量打到后端

实现方式：

- 基于IP的限流：单IP每秒最多100个请求
- 基于URI的限流：热点接口（如商品详情）单机QPS限制在5000
- 使用Nginx的limit_req_zone模块

### a. 限流算法： 漏桶算法（Leaky Bucket）

```
  配置示例：
  limit_req_zone $binary_remote_addr zone=ip_limit:10m rate=100r/s;
  limit_req_zone$uri zone=uri_limit:10m rate=5000r/s;
  location /api/product/detail {
      limit_req zone=uri_limit burst=1000 nodelay;
      limit_req zone=ip_limit burst=20;
  }
```

为什么用漏桶？

- 优势：流量平滑，不会有突刺
- 劣势：无法应对短时流量突增
- 所以设置了burst参数，允许一定的突发流量

---

## 2. 网关层限流（API Gateway）

目的： 按业务维度精细化限流

实现方式：

- 按用户维度限流：普通用户QPS=10，VIP用户QPS=50
- 按商家维度限流：S级商家QPS=1000，普通商家QPS=100
- 按接口维度限流：核心接口和非核心接口区别对待

### a. 限流算法： 令牌桶算法（Token Bucket）

为什么用令牌桶？

- 可以应对突发流量
- 更灵活，可以动态调整令牌生成速率

```
具体实现：
使用Redis + Lua脚本实现分布式令牌桶
-- Redis Lua脚本实现令牌桶
local key = KEYS[1]  -- 令牌桶key
local capacity = tonumber(ARGV[1])  -- 桶容量
local rate = tonumber(ARGV[2])  -- 令牌生成速率（个/秒）
local requested = tonumber(ARGV[3])  -- 请求的令牌数
local now = tonumber(ARGV[4])  -- 当前时间戳
local bucket = redis.call('HMGET', key, 'tokens', 'last_time')
local tokens = tonumber(bucket[1]) or capacity
local last_time = tonumber(bucket[2]) or now
-- 计算新增令牌数
local delta = math.max(0, now - last_time)
local new_tokens = math.min(capacity, tokens + delta * rate)
-- 判断是否有足够令牌
if new_tokens >= requested then
  new_tokens = new_tokens - requested
  redis.call('HMSET', key, 'tokens', new_tokens, 'last_time', now)
  redis.call('EXPIRE', key, 60)
  return 1  -- 允许通过
else
  return 0  -- 拒绝
end

执行逻辑：
允许通过：如果令牌充足
扣除所需令牌数
更新Redis中的令牌数和时间戳
设置60秒过期时间（防止key永久存在）
返回1表示允许
拒绝请求：如果令牌不足
直接返回0表示拒绝



调用示例
EVAL "脚本内容" 1 "rate_limit:user_123" 10 2 1 1703123456
参数含义：
"rate_limit:user_123": 用户123的限流key
10: 桶容量为10个令牌
2: 每秒生成2个令牌
1: 本次请求消耗1个令牌
1703123456: 当前时间戳
```

---

## 3. 应用层限流（Sentinel）

目的： 保护应用自身，防止被打挂

实现方式：  
使用阿里开源的Sentinel框架

限流维度：

1. 接口级限流：每个接口设置QPS阈值
2. 资源级限流：对关键资源（如DB查询、Redis查询）限流
3. 热点参数限流：对热点商品ID、热点商家ID单独限流

```
  核心代码示例：
  // 接口级限流
  @SentinelResource(value = "getProductDetail", blockHandler = "handleBlock",
                    fallback = "handleFallback")
  public ProductDTO getProductDetail(Long productId) {
      // 业务逻辑
  }
  // 热点参数限流
  ParamFlowRule rule = new ParamFlowRule("getProductDetail")
      .setParamIdx(0)  // 第0个参数（productId）
      .setCount(1000)  // 单个商品ID的QPS限制
      .setGrade(RuleConstant.FLOW_GRADE_QPS);
```

限流算法： 滑动窗口算法

为什么用滑动窗口？

- 比固定窗口更精确，避免窗口边界问题
- 比令牌桶更适合统计QPS

# 三、缓存层和数据层限流

## 1. Redis缓存层限流

目的： 防止缓存被打爆，保护Redis集群

实现方式：

### a. 连接池限流

```
JedisPoolConfig config = new JedisPoolConfig();
  config.setMaxTotal(500);      // 最大连接数
  config.setMaxIdle(100);       // 最大空闲连接
  config.setMaxWaitMillis(100); // 获取连接最大等待时间
  config.setTestOnBorrow(true);
  
```

为什么设置MaxWaitMillis=100ms？

- 如果100ms还拿不到连接，说明Redis已经过载
- 快速失败，避免请求堆积
- 触发降级逻辑，从本地缓存或DB读取

### b. 操作超时限流

// 设置Redis操作超时时间  
jedis.get(key, timeout=50ms); // 超过50ms直接超时

// 超时后的处理  
try {  
value = redis.get(key);  
} catch (TimeoutException e) {  
// 降级：从本地缓存读取  
value = localCache.get(key);  
if (value == null) {  
// 再降级：从DB读取  
value = db.query(key);  
}  
}

### c. 大key限流

- 问题：某些商家的商品列表特别大（几千个商品），一次查询返回几MB数据
- 方案：

- 检测value大小，超过1MB的拒绝写入Redis
- 大key拆分成多个小key
- 对大key的查询单独限流

---

## 2. 数据库层限流

目的： 保护MySQL，防止慢查询拖垮整个系统

实现方式：

### a. 连接池限流

  
HikariConfig config = new HikariConfig();  
config.setMaximumPoolSize(200); // 最大连接数  
config.setConnectionTimeout(1000); // 获取连接超时1秒  
config.setValidationTimeout(500); // 连接验证超时500ms  
config.setLeakDetectionThreshold(2000); // 连接泄漏检测

为什么最大连接数是200？

- 经过压测，单个MySQL实例最多支持300个并发连接
- 预留100个连接给其他系统
- 256个分库，每个库200个连接，总共需要51200个连接

### b. 慢查询熔断  

```
// 使用Hystrix对DB查询进行熔断
  @HystrixCommand(
      commandKey = "queryProduct",
      fallbackMethod = "queryProductFallback",
      commandProperties = {
          @HystrixProperty(name = "execution.isolation.thread.timeoutInMilliseconds",
                           value = "200"),  // 超时时间200ms
          @HystrixProperty(name = "circuitBreaker.requestVolumeThreshold",
                           value = "20"),   // 10秒内20个请求
          @HystrixProperty(name = "circuitBreaker.errorThresholdPercentage",
                           value = "50")    // 错误率50%触发熔断
      }
  )
  public Product queryProduct(Long id) {
      return productDao.selectById(id);
  }
  // 降级方法
  public Product queryProductFallback(Long id) {
      // 返回缓存的商品信息或默认值
      return localCache.get(id);
  }
```

### c. SQL执行时间限流

- 在JDBC层拦截，超过200ms的查询直接kill
- 记录慢查询日志，后续优化

```
// JDBC拦截器
  public class SlowQueryInterceptor implements Interceptor {
      @Override
      public Object intercept(Invocation invocation) throws Throwable {
          long start = System.currentTimeMillis();
          Object result = invocation.proceed();
          long cost = System.currentTimeMillis() - start;
      if (cost > 200) {
          // 记录慢查询
          logger.warn("Slow query detected: {}ms, SQL: {}", cost, sql);
          // 触发告警
          alertService.sendAlert("Slow query", sql);
      }
      return result;
  }
```

}

---

# 四、智能限流（动态调整阈值）

核心思想： 限流阈值不是固定的，而是根据系统负载、业务优先级动态调整

## 1. 基于系统负载的动态限流

实现逻辑：  
public class AdaptiveRateLimiter {  
// 基础QPS阈值  
private int baseQps = 10000;

```
  // 动态计算当前QPS阈值
  public int getCurrentQps() {
      // 获取系统指标
      double cpuUsage = SystemMetrics.getCpuUsage();
      double memUsage = SystemMetrics.getMemUsage();
      int activeThreads = SystemMetrics.getActiveThreads();

      // 计算负载因子（0-1之间）
      double loadFactor = calculateLoadFactor(cpuUsage, memUsage, activeThreads);

      // 动态调整QPS
      int currentQps = (int) (baseQps * (1 - loadFactor * 0.5));

      return Math.max(currentQps, baseQps / 2);  // 最低不低于50%
  }

  private double calculateLoadFactor(double cpu, double mem, int threads) {
      // CPU权重0.5，内存权重0.3，线程数权重0.2
      double cpuFactor = Math.max(0, (cpu - 0.7) / 0.3);  // CPU超过70%开始限流
      double memFactor = Math.max(0, (mem - 0.8) / 0.2);  // 内存超过80%开始限流
      double threadFactor = Math.max(0, (threads - 500) / 500.0);  // 线程超过500开始限流

      return cpuFactor * 0.5 + memFactor * 0.3 + threadFactor * 0.2;
  }
```

}

效果：

- 系统空闲时，QPS可以达到10000
- 系统负载高时，自动降低到5000，保护系统
- 避免了固定阈值的"一刀切"问题

---

## 2. 基于业务优先级的智能限流

商家分级策略：  
┌─────────────┬──────┬─────────┬─────────┬──────────────────┐  
│ 商家等级 │ 占比 │ 基础QPS │ 大促QPS │ 限流优先级 │  
├─────────────┼──────┼─────────┼─────────┼──────────────────┤  
│ S级（头部） │ 5% │ 10000 │ 50000 │ 最低（最后限流） │  
├─────────────┼──────┼─────────┼─────────┼──────────────────┤  
│ A级（重点） │ 15% │ 5000 │ 20000 │ 低 │  
├─────────────┼──────┼─────────┼─────────┼──────────────────┤  
│ B级（普通） │ 30% │ 1000 │ 5000 │ 中 │  
├─────────────┼──────┼─────────┼─────────┼──────────────────┤  
│ C级（长尾） │ 50% │ 100 │ 500 │ 高（优先限流） │  
└─────────────┴──────┴─────────┴─────────┴──────────────────┘  
实现代码：  
public class PriorityRateLimiter {

```
  // 商家等级配置
  private Map<String, MerchantConfig> merchantConfigs;

  public boolean allowRequest(Long merchantId, String api) {
      // 获取商家等级
      String level = getMerchantLevel(merchantId);
      MerchantConfig config = merchantConfigs.get(level);

      // 获取当前QPS
      int currentQps = getCurrentQps(merchantId, api);

      // 判断是否超过限流阈值
      if (currentQps > config.getMaxQps()) {
          // 根据优先级决定是否放行
          return shouldAllowByPriority(level, currentQps);
      }

      return true;
  }

  private boolean shouldAllowByPriority(String level, int currentQps) {
      // S级商家：即使超过阈值，也有80%概率放行
      if ("S".equals(level)) {
          return Math.random() < 0.8;
      }
      // A级商家：50%概率放行
      if ("A".equals(level)) {
          return Math.random() < 0.5;
      }
      // B级和C级：直接拒绝
      return false;
  }
}  
```

# 五、限流后的降级策略

核心思想

当系统触发限流后，我们的策略不是简单粗暴地返回"系统繁忙，请稍后再试"，而是尽最大努力给用户返回有价值的信息。这就是降级的核心思想。

为什么要分级降级？

在外卖场景下，用户体验非常重要。如果直接返回错误，用户可能就流失了。所以我们设计了4级降级策略：

- Level 1：从缓存读取，数据可能延迟几秒，但基本准确
- Level 2：从本地缓存读取，数据可能延迟几十秒，但总比没有强
- Level 3：返回简化数据，只包含核心信息（商品名、价格、图片）
- Level 4：返回默认数据或友好提示

实际案例：商品详情接口的降级

正常情况（Level 0）：  
用户点击一个商品，我们会返回：

- 商品基本信息（名称、价格、图片、描述）
- 用户评价（最新100条）
- 销量信息（今日销量、总销量）
- 推荐商品（基于算法推荐的相似商品）

这需要查询4个服务，总耗时约100ms。

限流后（Level 1）：  
直接从Redis缓存读取完整数据，虽然可能是30秒前的数据，但对用户来说基本无感知。耗时降到10ms。

Redis也挂了（Level 2）：  
从应用本地缓存读取，数据可能是5分钟前的。我们会在页面上标注"数据可能有延迟"，但至少用户能看到商品信息。

所有缓存都miss（Level 3）：  
只返回商品的核心信息（从商品基础表查询），不包含评价、销量、推荐等。页面会显示"评价加载中..."，但不影响用户下单。

彻底失败（Level 4）：  
返回一个默认商品信息，或者友好提示"商品信息暂时无法加载，请稍后再试"。

---

降级的业务影响分析

我们做过统计：  
┌──────────┬──────────┬──────────────┬────────────┐  
│ 降级级别 │ 触发频率 │ 用户体验影响 │ 转化率影响 │  
├──────────┼──────────┼──────────────┼────────────┤  
│ Level 1 │ 5% │ 几乎无感知 │ -0.5% │  
├──────────┼──────────┼──────────────┼────────────┤  
│ Level 2 │ 1% │ 轻微延迟感 │ -2% │  
├──────────┼──────────┼──────────────┼────────────┤  
│ Level 3 │ 0.1% │ 明显简化 │ -10% │  
├──────────┼──────────┼──────────────┼────────────┤  
│ Level 4 │ 0.01% │ 无法使用 │ -100% │  
└──────────┴──────────┴──────────────┴────────────┘  
所以我们的目标是：尽量让降级停留在Level 1和Level 2，避免到Level 3和Level 4。

---

降级配置的动态调整

降级策略不是写死的，而是可以通过配置中心动态调整。比如：

大促期间：

- Level 1的缓存时间从30秒延长到60秒（容忍更长的数据延迟）
- Level 3的简化程度更高（只返回最核心的字段）
- 提前预热缓存，降低Level 2的触发概率

日常时段：

- 恢复正常配置
- Level 3和Level 4基本不会触发

---

## 降级的自动恢复机制

这是一个很关键的设计。降级后不能一直降级，需要自动探测系统是否恢复。

恢复策略：

1. 健康检查：每10秒发送一次探测请求，检查系统是否恢复
2. 连续成功判定：连续3次探测成功，才认为系统恢复
3. 灰度恢复：不是一次性全部恢复，而是逐步放量（10% → 30% → 50% → 100%）
4. 快速降级：如果恢复后又出现问题，立即重新降级

为什么要灰度恢复？

如果系统刚恢复就放开全部流量，可能会再次被打挂，导致"降级-恢复-降级"的循环。灰度恢复可以让系统逐步适应流量。

---

# 六、限流监控和告警体系

为什么监控很重要？

限流和降级都是被动防御，我们更希望提前发现问题，在触发限流之前就进行干预。所以需要完善的监控体系。

监控的三个层次

1. 实时监控（秒级）

- 目的：快速发现异常流量
- 指标：QPS、错误率、响应时间
- 告警：QPS突增50%、错误率超过1%

2. 趋势监控（分钟级）

- 目的：发现性能劣化趋势
- 指标：P99响应时间、限流触发次数、降级次数
- 告警：P99持续上升、限流次数持续增加

3. 容量监控（小时级/天级）

- 目的：容量规划
- 指标：峰值QPS、平均QPS、资源使用率
- 告警：峰值QPS接近系统容量上限

---
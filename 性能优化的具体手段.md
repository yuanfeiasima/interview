# 性能优化的具体手段

## 核心要点（面试快速回答）

**Q: P99从120ms优化到50ms，具体做了哪些优化？**
四个层面：1）代码层：异步化改造、批量查询合并、序列化优化（JSON→Protobuf）；2）缓存层：本地缓存命中率从20%提升到30%，缓存预热；3）数据库层：慢SQL优化、索引优化、连接池调优；4）架构层：SET化部署降低网络延迟。其中效果最明显的是慢SQL优化（贡献30ms）和本地缓存优化（贡献20ms）。

**Q: 最有效的优化案例是什么？**
商品列表接口优化。原来是串行查询5个服务，改成并行后RT从150ms降到60ms。再加上批量查询合并（10次Redis查询合并成1次Pipeline），RT进一步降到35ms。

**Q: 如何量化每个优化的收益？**
每次优化前后做A/B测试，对比P50、P99、错误率。用APM工具（如CAT、SkyWalking）追踪每个环节的耗时。建立性能基线，每周自动生成性能报告，发现劣化及时告警。

**Q: 优化有没有遇到什么坑？**
有。过度异步化导致线程池打满；批量查询数据量太大导致超时；本地缓存命中率提升后，缓存一致性问题更明显。每个优化都要考虑副作用。

---

## 一、优化前的性能基线

### 1.1 优化前指标

```
商品详情接口（核心接口）：
- P50：60ms
- P99：120ms
- 错误率：0.1%
- QPS：30万

商品列表接口：
- P50：80ms
- P99：150ms
- 错误率：0.2%
- QPS：45万

目标：
- P99 < 50ms
- 错误率 < 0.05%
```

### 1.2 性能瓶颈分析

通过APM工具分析，发现主要耗时分布：

```
商品详情接口耗时分解（P99=120ms）：
├─ 网络传输：10ms (8%)
├─ 序列化/反序列化：15ms (12%)
├─ Redis查询：20ms (17%)
├─ DB查询：50ms (42%)
├─ 业务逻辑：15ms (13%)
└─ 其他（GC等）：10ms (8%)
```

**核心问题：**
1. DB查询耗时占比过高（42%）
2. 存在多次串行调用
3. 序列化开销较大
4. 缓存命中率不够高

---

## 二、代码层优化

### 2.1 异步化改造

**问题：串行调用多个服务**
```java
// 优化前：串行调用，总耗时 = 各服务耗时之和
public ProductDetailDTO getProductDetail(Long productId) {
    Product product = productService.getById(productId);      // 30ms
    List<Review> reviews = reviewService.getByProductId(productId); // 40ms
    List<Product> recommends = recommendService.getRecommends(productId); // 50ms
    StockInfo stock = stockService.getStock(productId);        // 20ms
    // 总耗时：140ms
    return buildDTO(product, reviews, recommends, stock);
}
```

**优化：并行调用**
```java
// 优化后：并行调用，总耗时 = 最长服务耗时
public ProductDetailDTO getProductDetail(Long productId) {
    CompletableFuture<Product> productFuture =
        CompletableFuture.supplyAsync(() -> productService.getById(productId));

    CompletableFuture<List<Review>> reviewsFuture =
        CompletableFuture.supplyAsync(() -> reviewService.getByProductId(productId));

    CompletableFuture<List<Product>> recommendsFuture =
        CompletableFuture.supplyAsync(() -> recommendService.getRecommends(productId));

    CompletableFuture<StockInfo> stockFuture =
        CompletableFuture.supplyAsync(() -> stockService.getStock(productId));

    // 等待所有任务完成，总耗时：50ms（最长的recommend服务）
    CompletableFuture.allOf(productFuture, reviewsFuture, recommendsFuture, stockFuture).join();

    return buildDTO(
        productFuture.get(),
        reviewsFuture.get(),
        recommendsFuture.get(),
        stockFuture.get()
    );
}
```

**效果：** RT从140ms降到55ms，降幅60%

**注意事项：**
- 需要合理配置线程池大小
- 设置合理的超时时间
- 某个服务失败不应影响整体

### 2.2 批量查询合并

**问题：循环查询Redis**
```java
// 优化前：N次Redis查询
public List<ProductDTO> getProducts(List<Long> productIds) {
    List<ProductDTO> result = new ArrayList<>();
    for (Long id : productIds) {
        ProductDTO product = redisTemplate.opsForValue().get("product:" + id);
        result.add(product);
    }
    // 10个商品 = 10次网络往返 = 10 * 5ms = 50ms
    return result;
}
```

**优化：使用Pipeline批量查询**
```java
// 优化后：1次Pipeline查询
public List<ProductDTO> getProducts(List<Long> productIds) {
    List<String> keys = productIds.stream()
        .map(id -> "product:" + id)
        .collect(Collectors.toList());

    // 使用Pipeline，1次网络往返
    List<ProductDTO> result = redisTemplate.opsForValue().multiGet(keys);
    // 10个商品 = 1次网络往返 = 8ms
    return result;
}
```

**效果：** 批量查询RT从50ms降到8ms，降幅84%

**进一步优化：本地聚合**
```java
// 先查本地缓存，miss的再批量查Redis
public List<ProductDTO> getProductsOptimized(List<Long> productIds) {
    Map<Long, ProductDTO> result = new HashMap<>();
    List<Long> missIds = new ArrayList<>();

    // 1. 先查本地缓存
    for (Long id : productIds) {
        ProductDTO cached = localCache.getIfPresent(id);
        if (cached != null) {
            result.put(id, cached);
        } else {
            missIds.add(id);
        }
    }

    // 2. miss的批量查Redis
    if (!missIds.isEmpty()) {
        List<ProductDTO> fromRedis = batchGetFromRedis(missIds);
        for (ProductDTO product : fromRedis) {
            result.put(product.getId(), product);
            localCache.put(product.getId(), product);  // 回填本地缓存
        }
    }

    // 3. 保持原有顺序返回
    return productIds.stream()
        .map(result::get)
        .collect(Collectors.toList());
}
```

### 2.3 序列化优化

**问题：JSON序列化开销大**
```java
// 优化前：使用JSON序列化
// 单次序列化耗时：2-5ms
// 对象大小：10KB
String json = JSON.toJSONString(product);
ProductDTO product = JSON.parseObject(json, ProductDTO.class);
```

**优化：改用Protobuf**
```protobuf
// product.proto
message ProductDTO {
    int64 id = 1;
    string name = 2;
    int32 price = 3;
    string image = 4;
    repeated string tags = 5;
}
```

```java
// 优化后：使用Protobuf
// 单次序列化耗时：0.5-1ms
// 对象大小：3KB
byte[] bytes = product.toByteArray();
ProductDTO product = ProductDTO.parseFrom(bytes);
```

**效果对比：**

| 指标 | JSON | Protobuf | 提升 |
|-----|------|----------|-----|
| 序列化耗时 | 3ms | 0.8ms | 73% |
| 反序列化耗时 | 2ms | 0.5ms | 75% |
| 数据大小 | 10KB | 3KB | 70% |

**注意：** 不是所有场景都适合Protobuf
- 调试不方便（二进制格式）
- 需要维护proto文件
- 对外接口还是用JSON

### 2.4 对象池化

**问题：频繁创建对象导致GC压力**
```java
// 优化前：每次请求创建新对象
public void processRequest() {
    byte[] buffer = new byte[1024];  // 每次创建
    StringBuilder sb = new StringBuilder();  // 每次创建
    // ...
}
```

**优化：对象池复用**
```java
// 使用对象池
private static final ObjectPool<byte[]> BUFFER_POOL =
    new ObjectPool<>(() -> new byte[1024], 1000);

public void processRequest() {
    byte[] buffer = BUFFER_POOL.borrow();
    try {
        // 使用buffer
    } finally {
        BUFFER_POOL.release(buffer);
    }
}
```

**效果：** Young GC次数减少40%，GC停顿时间减少30%

---

## 三、缓存层优化

### 3.1 本地缓存命中率提升

**问题：本地缓存命中率只有20%**

**分析原因：**
1. 缓存容量不够，热点数据装不下
2. 缓存淘汰策略不合理
3. 没有预热机制

**优化措施：**

**措施1：扩大缓存容量**
```java
// 优化前：1GB本地缓存
Caffeine.newBuilder()
    .maximumSize(100_000)  // 10万条
    .build();

// 优化后：10GB本地缓存
Caffeine.newBuilder()
    .maximumSize(1_000_000)  // 100万条
    .build();
```

**措施2：优化淘汰策略**
```java
// 使用W-TinyLFU算法（Caffeine默认）
// 比LRU更适合应对突发流量
Caffeine.newBuilder()
    .maximumSize(1_000_000)
    .expireAfterWrite(30, TimeUnit.SECONDS)
    .recordStats()  // 开启统计
    .build();
```

**措施3：缓存预热**
```java
@Component
public class CacheWarmer {

    @PostConstruct
    public void warmUp() {
        // 应用启动时预热热点数据
        List<Long> hotProductIds = getHotProductIds();  // 获取Top 10万热点商品
        for (Long productId : hotProductIds) {
            ProductDTO product = loadFromRedis(productId);
            localCache.put(productId, product);
        }
        log.info("Cache warmed up with {} products", hotProductIds.size());
    }

    // 定时刷新热点数据
    @Scheduled(fixedRate = 300000)  // 每5分钟
    public void refreshHotData() {
        List<Long> hotProductIds = getRealtimeHotProductIds();
        for (Long productId : hotProductIds) {
            ProductDTO product = loadFromRedis(productId);
            localCache.put(productId, product);
        }
    }
}
```

**效果：** 本地缓存命中率从20%提升到32%

### 3.2 Redis查询优化

**优化1：使用本地Redis代理**
```
优化前：应用 → Redis集群（跨机房）
RT：5ms

优化后：应用 → 本地Redis代理 → Redis集群
RT：2ms（代理有本地缓存）
```

**优化2：连接池调优**
```java
// 优化前：默认配置
JedisPoolConfig config = new JedisPoolConfig();

// 优化后：根据QPS调优
JedisPoolConfig config = new JedisPoolConfig();
config.setMaxTotal(500);           // 最大连接数
config.setMaxIdle(100);            // 最大空闲连接
config.setMinIdle(50);             // 最小空闲连接（预热）
config.setMaxWaitMillis(100);      // 获取连接最大等待时间
config.setTestOnBorrow(false);     // 关闭借用检测（提升性能）
config.setTestWhileIdle(true);     // 空闲时检测
```

**优化3：合理设置超时**
```java
// 连接超时：100ms
// 读超时：50ms
// 写超时：50ms
Jedis jedis = new Jedis(host, port, 100, 50);
```

---

## 四、数据库层优化

### 4.1 慢SQL优化

**问题：商品列表查询慢**
```sql
-- 优化前：全表扫描
SELECT * FROM product
WHERE merchant_id = 123
AND status = 1
ORDER BY update_time DESC
LIMIT 20;

-- 执行计划显示：type=ALL，扫描100万行
-- 耗时：200ms
```

**优化：添加复合索引**
```sql
-- 添加索引
CREATE INDEX idx_merchant_status_time
ON product(merchant_id, status, update_time DESC);

-- 优化后：索引扫描
-- 执行计划显示：type=ref，扫描20行
-- 耗时：5ms
```

**效果：** 单次查询从200ms降到5ms

**更多SQL优化案例：**

| 场景 | 优化前 | 优化后 | 优化手段 |
|-----|-------|-------|---------|
| 商品列表 | 200ms | 5ms | 复合索引 |
| 商品搜索 | 500ms | 20ms | 覆盖索引 |
| 统计查询 | 2s | 100ms | 预计算 + 缓存 |
| 批量更新 | 1s | 50ms | 批量SQL |

### 4.2 索引优化

**原则：**
1. 查询字段放前面
2. 区分度高的字段放前面
3. 避免过度索引

**商品表索引设计：**
```sql
-- 主键索引
PRIMARY KEY (id)

-- 业务查询索引
INDEX idx_merchant_status (merchant_id, status)  -- 商家商品列表
INDEX idx_category_status (category_id, status)  -- 分类商品列表
INDEX idx_name (name)  -- 商品名称搜索（配合ES使用）

-- 时间范围索引
INDEX idx_create_time (create_time)  -- 按时间查询
INDEX idx_update_time (update_time)  -- 增量同步
```

### 4.3 连接池优化

```java
// HikariCP配置优化
HikariConfig config = new HikariConfig();

// 连接数配置
config.setMaximumPoolSize(50);      // 最大连接数
config.setMinimumIdle(10);          // 最小空闲连接

// 超时配置
config.setConnectionTimeout(3000);   // 获取连接超时3秒
config.setIdleTimeout(600000);       // 空闲连接超时10分钟
config.setMaxLifetime(1800000);      // 连接最大生命周期30分钟

// 性能配置
config.setAutoCommit(true);
config.addDataSourceProperty("cachePrepStmts", "true");
config.addDataSourceProperty("prepStmtCacheSize", "250");
config.addDataSourceProperty("prepStmtCacheSqlLimit", "2048");
```

**连接数计算公式：**
```
最大连接数 = (核心数 * 2) + 有效磁盘数
例：8核CPU + 1块SSD = 8 * 2 + 1 = 17

实际配置时会预留冗余：
- 单实例：50个连接
- 256个分库 * 50 = 12800个连接（总量）
```

---

## 五、架构层优化

### 5.1 SET化部署

**问题：跨地域调用延迟高**
```
北京用户 → 上海机房
网络延迟：30ms
商品详情接口需要3次调用 = 90ms网络延迟
```

**优化：SET化部署**
```
北京用户 → 北京机房
网络延迟：3ms
商品详情接口3次调用 = 9ms网络延迟
```

**效果：** 跨地域请求RT降低70%

### 5.2 读写分离

```java
// 读写分离配置
@Configuration
public class DataSourceConfig {

    @Bean
    @Primary
    public DataSource routingDataSource() {
        RoutingDataSource routingDataSource = new RoutingDataSource();

        Map<Object, Object> targetDataSources = new HashMap<>();
        targetDataSources.put("master", masterDataSource());
        targetDataSources.put("slave1", slave1DataSource());
        targetDataSources.put("slave2", slave2DataSource());

        routingDataSource.setTargetDataSources(targetDataSources);
        routingDataSource.setDefaultTargetDataSource(masterDataSource());

        return routingDataSource;
    }
}

// 使用注解指定数据源
@ReadOnly  // 自定义注解，路由到从库
public Product getProduct(Long id) {
    return productDao.selectById(id);
}

@Transactional  // 写操作走主库
public void updateProduct(Product product) {
    productDao.update(product);
}
```

**效果：** 主库压力降低60%，读接口RT降低20%

---

## 六、JVM调优

### 6.1 GC优化

**优化前：**
```
-Xms4g -Xmx4g
-XX:+UseParallelGC

问题：
- Full GC频繁，每次停顿200ms
- Young GC每秒2-3次
```

**优化后：**
```
-Xms8g -Xmx8g
-XX:+UseG1GC
-XX:MaxGCPauseMillis=50
-XX:G1HeapRegionSize=16m
-XX:InitiatingHeapOccupancyPercent=45

效果：
- Full GC基本消除
- Young GC停顿时间 < 20ms
- P99延迟更稳定
```

### 6.2 JIT优化

```
# 开启分层编译
-XX:+TieredCompilation

# 调整编译阈值
-XX:CompileThreshold=5000

# 预热关键方法
应用启动时，主动调用核心接口1000次
```

---

## 七、性能优化效果汇总

### 7.1 各优化措施收益

| 优化措施 | RT降低 | 占比 |
|---------|-------|-----|
| 慢SQL优化 | 30ms | 43% |
| 本地缓存优化 | 20ms | 29% |
| 异步化改造 | 10ms | 14% |
| 序列化优化 | 5ms | 7% |
| 其他优化 | 5ms | 7% |
| **总计** | **70ms** | **100%** |

### 7.2 优化前后对比

| 指标 | 优化前 | 优化后 | 提升 |
|-----|-------|-------|-----|
| P50 | 60ms | 25ms | 58% |
| P99 | 120ms | 50ms | 58% |
| 错误率 | 0.1% | 0.03% | 70% |
| QPS上限 | 50万 | 100万 | 100% |

---

## 八、性能优化方法论

### 8.1 优化流程

```
1. 建立基线
   └─ 记录当前P50、P99、错误率

2. 定位瓶颈
   └─ 使用APM工具分析耗时分布

3. 制定方案
   └─ 针对瓶颈点设计优化方案

4. 验证效果
   └─ A/B测试，对比优化前后指标

5. 监控回归
   └─ 持续监控，发现性能劣化
```

### 8.2 常用工具

| 工具 | 用途 |
|-----|-----|
| Arthas | 线上诊断，方法耗时分析 |
| SkyWalking | 分布式链路追踪 |
| JProfiler | 内存、CPU分析 |
| pt-query-digest | MySQL慢查询分析 |
| redis-cli --latency | Redis延迟分析 |

### 8.3 避坑指南

**坑1：过度优化**
- 不要为了优化1ms花一周时间
- 先优化瓶颈点，收益最大

**坑2：优化引入新问题**
- 异步化可能导致线程池打满
- 批量查询可能导致大key问题
- 每个优化都要评估副作用

**坑3：只看平均值**
- 平均RT看起来好，但P99可能很差
- 要关注长尾延迟

**坑4：优化后不监控**
- 优化效果可能随时间衰减
- 需要持续监控，定期review

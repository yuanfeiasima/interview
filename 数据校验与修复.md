# 数据校验与修复

## 核心要点（面试快速回答）

**Q: 如何保证缓存、DB、ES之间的数据一致性？**
三层保障：1）实时同步：Canal监听binlog，变更后秒级同步到缓存和ES；2）定时对账：每小时抽样比对，发现不一致自动修复；3）全量校验：每天凌晨全量扫描，生成一致性报告。目标是不一致率<0.01%。

**Q: 发现不一致后如何修复？**
以DB为准进行修复。优先级：1）影响交易的数据（价格、库存、状态）立即修复；2）影响展示的数据（描述、图片）批量修复；3）历史数据定期清理。修复方式有自动修复（对账任务）和人工修复（管理后台）。

**Q: 百亿数据规模下对账怎么做？**
分治策略：按商家ID分片并行对账，每个分片独立执行。采用增量对账（基于binlog）+抽样全量对账（每天10%数据）的组合方式。全量对账用Spark离线任务跑，不影响线上。

**Q: 遇到过严重的数据不一致问题吗？**
遇到过。某次ES集群故障恢复后，约5%商品索引丢失，导致搜索不到。处理方式：紧急从DB全量重建索引，耗时4小时。后来增加了ES和DB的实时对账告警。

---

## 一、数据一致性挑战

### 1.1 数据存储全景

```
商品数据分布在多个存储系统：

┌─────────────────────────────────────────────────────────┐
│                        商品数据                          │
├─────────────┬─────────────┬─────────────┬──────────────┤
│   MySQL     │   Redis     │     ES      │    本地缓存   │
│  (主存储)   │  (热数据)   │  (搜索)     │   (极热)     │
├─────────────┼─────────────┼─────────────┼──────────────┤
│  50亿商品   │  5000万     │   5亿       │   100万/机器 │
│  全量数据   │  活跃商品   │  可搜索商品  │   热点商品   │
│  强一致     │  最终一致   │  最终一致    │   最终一致   │
└─────────────┴─────────────┴─────────────┴──────────────┘
```

### 1.2 不一致的常见原因

| 原因 | 场景 | 影响 |
|-----|-----|-----|
| 同步延迟 | Canal/MQ处理慢 | 缓存/ES数据滞后 |
| 消息丢失 | MQ故障、网络抖动 | 部分数据未同步 |
| 同步失败 | ES/Redis写入失败 | 数据缺失 |
| 并发写入 | 同时更新多个存储 | 数据不一致 |
| 系统故障 | 存储系统宕机恢复 | 数据丢失或回滚 |
| 人工操作 | 直接修改DB | 未同步到其他系统 |

---

## 二、实时同步机制

### 2.1 基于Canal的数据同步

**为什么选择Canal**：Canal是阿里开源的MySQL binlog增量订阅组件。选择它的原因是：1）对业务代码无侵入，不需要在每个写操作后手动发消息；2）基于binlog，保证不会漏数据；3）已在阿里大规模验证过。缺点是引入了新组件，增加了运维复杂度。

**同步架构的核心思想**：DB变更 → Canal解析binlog → 发送MQ → 各系统消费。这样的好处是解耦：DB只管写，不用关心谁需要这个数据；各消费方独立消费，互不影响。

```
数据同步架构：

MySQL binlog → Canal → MQ → 各消费端
                              ├─ Redis缓存服务
                              ├─ ES索引服务
                              ├─ 本地缓存广播
                              └─ 数据仓库

同步延迟目标：< 1秒
```

**Canal消费者实现：**

**关键设计点**：
1. 每条消息都有唯一的messageId，用于追踪和去重
2. 消费结果记录到同步结果表，便于监控和重试
3. 异常时抛出异常让MQ重试，而不是静默失败

```java
@Component
public class ProductDataSyncListener {

    @CanalEventListener(destination = "product_db", table = "product")
    public void onProductChange(CanalEntry.RowChange rowChange) {
        for (CanalEntry.RowData rowData : rowChange.getRowDatasList()) {
            Long productId = getProductId(rowData);
            EventType eventType = rowChange.getEventType();

            // 构建同步消息
            DataSyncMessage message = new DataSyncMessage();
            message.setMessageId(UUID.randomUUID().toString());
            message.setProductId(productId);
            message.setEventType(eventType.name());
            message.setData(buildProductData(rowData));
            message.setTimestamp(System.currentTimeMillis());

            // 发送到MQ
            mqProducer.send("product_data_sync", message);

            log.info("Product data sync: productId={}, event={}",
                productId, eventType);
        }
    }
}
```

**各系统消费处理：**

**消费者设计要点**：
1. Redis消费者：UPDATE/INSERT时写入缓存，DELETE时删除缓存
2. ES消费者：额外判断商品状态，只有上架商品才建索引，下架商品要从ES删除
3. 每个消费者都要确认消费结果，失败时让MQ重试
4. 使用不同的consumerGroup，保证各系统独立消费

```java
// Redis缓存同步
@RocketMQMessageListener(topic = "product_data_sync",
    consumerGroup = "redis_sync_group")
public class RedisSyncConsumer {

    public void onMessage(DataSyncMessage message) {
        try {
            if ("DELETE".equals(message.getEventType())) {
                redisTemplate.delete("product:" + message.getProductId());
            } else {
                Product product = JSON.parseObject(message.getData(), Product.class);
                redisTemplate.opsForValue().set(
                    "product:" + message.getProductId(),
                    product,
                    5, TimeUnit.MINUTES);
            }

            // 确认消费成功
            syncResultService.confirm(message.getMessageId(), "REDIS", "SUCCESS");

        } catch (Exception e) {
            log.error("Redis sync failed: {}", message.getProductId(), e);
            syncResultService.confirm(message.getMessageId(), "REDIS", "FAILED");
            throw e;  // 重试
        }
    }
}

// ES索引同步
@RocketMQMessageListener(topic = "product_data_sync",
    consumerGroup = "es_sync_group")
public class EsSyncConsumer {

    public void onMessage(DataSyncMessage message) {
        try {
            if ("DELETE".equals(message.getEventType())) {
                esClient.delete("product", message.getProductId().toString());
            } else {
                Product product = JSON.parseObject(message.getData(), Product.class);
                // 只有上架商品才索引
                if (product.getStatus() == ProductStatus.ON_SHELF) {
                    esClient.index("product", product.getId().toString(), product);
                } else {
                    esClient.delete("product", product.getId().toString());
                }
            }

            syncResultService.confirm(message.getMessageId(), "ES", "SUCCESS");

        } catch (Exception e) {
            log.error("ES sync failed: {}", message.getProductId(), e);
            syncResultService.confirm(message.getMessageId(), "ES", "FAILED");
            throw e;
        }
    }
}
```

### 2.2 同步结果追踪

**为什么需要追踪表**：MQ消费可能失败，失败后需要重试。追踪表记录每条消息的处理状态，定时任务扫描失败记录进行重试。超过重试次数的告警人工处理。这是"可观测性"的体现——任何异步操作都要有追踪机制。

```java
// 同步结果表
CREATE TABLE data_sync_result (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    message_id VARCHAR(64) NOT NULL,
    product_id BIGINT NOT NULL,
    target_system VARCHAR(32) NOT NULL,  -- REDIS/ES/LOCAL_CACHE
    status VARCHAR(16) NOT NULL,          -- SUCCESS/FAILED/PENDING
    retry_count INT DEFAULT 0,
    create_time DATETIME,
    update_time DATETIME,
    INDEX idx_message_id (message_id),
    INDEX idx_status_time (status, create_time)
);

// 同步失败重试任务
@Scheduled(fixedRate = 60000)  // 每分钟
public void retrySyncFailed() {
    List<DataSyncResult> failedRecords = syncResultDao
        .selectByStatus("FAILED", 100);

    for (DataSyncResult record : failedRecords) {
        if (record.getRetryCount() >= 3) {
            // 超过重试次数，告警人工处理
            alertService.send("数据同步失败超过3次: " + record.getMessageId());
            record.setStatus("ALERT");
            syncResultDao.update(record);
            continue;
        }

        // 重新发送消息
        DataSyncMessage message = messageDao.selectById(record.getMessageId());
        mqProducer.send("product_data_sync", message);
        record.setRetryCount(record.getRetryCount() + 1);
        syncResultDao.update(record);
    }
}
```

---

## 三、定时对账机制

### 3.1 对账任务设计

```
对账策略：

1. 增量对账（每小时）
   - 基于最近1小时的变更记录
   - 比对变更商品在各系统的数据
   - 发现不一致立即修复

2. 抽样全量对账（每天）
   - 随机抽取10%的商品
   - 比对DB、Redis、ES的数据
   - 生成一致性报告

3. 全量对账（每周）
   - Spark离线任务
   - 比对全量数据
   - 生成详细报告
```

### 3.2 增量对账实现

**增量对账的思路**：不需要全量扫描，只检查"最近变更过的数据"。通过DB的update_time字段筛选出最近1小时变更的商品，然后比对这些商品在DB、Redis、ES中的数据是否一致。这样对账范围小，对线上影响也小。

**自动修复策略**：发现不一致后以DB为准自动修复。修复也要记录，便于分析不一致的原因和频率。

```java
@Scheduled(cron = "0 0 * * * ?")  // 每小时执行
public void incrementalReconcile() {
    log.info("Starting incremental reconciliation...");

    // 获取最近1小时的变更商品
    Date startTime = DateUtils.addHours(new Date(), -1);
    List<Long> changedProductIds = productDao.selectChangedIds(startTime);

    log.info("Found {} changed products", changedProductIds.size());

    ReconcileResult result = new ReconcileResult();
    result.setStartTime(new Date());
    result.setType("INCREMENTAL");

    // 分批处理
    List<List<Long>> batches = Lists.partition(changedProductIds, 100);
    for (List<Long> batch : batches) {
        reconcileBatch(batch, result);
    }

    result.setEndTime(new Date());
    result.setTotalCount(changedProductIds.size());

    // 保存对账结果
    reconcileResultDao.insert(result);

    // 发送报告
    sendReconcileReport(result);
}

private void reconcileBatch(List<Long> productIds, ReconcileResult result) {
    // 批量获取各系统数据
    Map<Long, Product> dbProducts = productDao.batchSelect(productIds);
    Map<Long, Product> redisProducts = redisBatchGet(productIds);
    Map<Long, Product> esProducts = esBatchGet(productIds);

    for (Long productId : productIds) {
        Product dbProduct = dbProducts.get(productId);
        Product redisProduct = redisProducts.get(productId);
        Product esProduct = esProducts.get(productId);

        // 比对Redis
        if (!isConsistent(dbProduct, redisProduct)) {
            result.addRedisInconsistent(productId);
            // 自动修复
            if (dbProduct != null) {
                redisTemplate.opsForValue().set("product:" + productId, dbProduct);
            } else {
                redisTemplate.delete("product:" + productId);
            }
            result.addFixed(productId, "REDIS");
        }

        // 比对ES
        if (!isEsConsistent(dbProduct, esProduct)) {
            result.addEsInconsistent(productId);
            // 自动修复
            if (dbProduct != null && dbProduct.getStatus() == ProductStatus.ON_SHELF) {
                esClient.index("product", productId.toString(), dbProduct);
            } else {
                esClient.delete("product", productId.toString());
            }
            result.addFixed(productId, "ES");
        }
    }
}
```

### 3.3 一致性比对逻辑

**比对策略的关键点**：
1. DB和Redis比对：比对所有关键字段（ID、名称、价格、状态、库存），任一不同就算不一致
2. DB和ES比对：ES只存上架商品，所以下架商品在ES中不存在是正常的，不算不一致
3. 比对字段要精心选择：太少可能漏检，太多可能误报（比如更新时间差异不重要）

```java
public class DataConsistencyChecker {

    // DB和Redis的比对
    public boolean isConsistent(Product dbProduct, Product redisProduct) {
        if (dbProduct == null && redisProduct == null) {
            return true;
        }
        if (dbProduct == null || redisProduct == null) {
            return false;
        }

        // 比对关键字段
        return Objects.equals(dbProduct.getId(), redisProduct.getId())
            && Objects.equals(dbProduct.getName(), redisProduct.getName())
            && Objects.equals(dbProduct.getPrice(), redisProduct.getPrice())
            && Objects.equals(dbProduct.getStatus(), redisProduct.getStatus())
            && Objects.equals(dbProduct.getStock(), redisProduct.getStock());
    }

    // DB和ES的比对
    public boolean isEsConsistent(Product dbProduct, Product esProduct) {
        // ES只存储上架商品
        if (dbProduct == null || dbProduct.getStatus() != ProductStatus.ON_SHELF) {
            // DB没有或已下架，ES应该也没有
            return esProduct == null;
        }

        if (esProduct == null) {
            // DB有且上架，但ES没有
            return false;
        }

        // 比对关键字段
        return Objects.equals(dbProduct.getId(), esProduct.getId())
            && Objects.equals(dbProduct.getName(), esProduct.getName())
            && Objects.equals(dbProduct.getPrice(), esProduct.getPrice())
            && Objects.equals(dbProduct.getCategoryId(), esProduct.getCategoryId());
    }
}
```

### 3.4 全量对账（Spark任务）

**为什么用Spark**：百亿数据的全量对账不能在线上跑，会影响正常服务。用Spark离线任务，从DB从库和ES集群读取数据进行对比，结果写入HDFS，不影响线上。这是"计算密集型任务离线化"的典型应用。

**LEFT JOIN的技巧**：用left_outer join，DB数据作为左表，这样能发现"DB有但ES没有"的情况（ES字段为null）。

```java
// Spark全量对账任务
public class FullReconcileJob {

    public void run() {
        SparkSession spark = SparkSession.builder()
            .appName("ProductFullReconcile")
            .getOrCreate();

        // 读取MySQL全量数据
        Dataset<Row> dbData = spark.read()
            .jdbc(dbUrl, "product", dbProperties);

        // 读取ES全量数据
        Dataset<Row> esData = spark.read()
            .format("org.elasticsearch.spark.sql")
            .load("product");

        // 左连接比对
        Dataset<Row> result = dbData.alias("db")
            .join(esData.alias("es"),
                col("db.id").equalTo(col("es.id")),
                "left_outer")
            .select(
                col("db.id"),
                col("db.name").alias("db_name"),
                col("es.name").alias("es_name"),
                col("db.price").alias("db_price"),
                col("es.price").alias("es_price"),
                col("db.status").alias("db_status")
            )
            .filter(
                // 找出不一致的记录
                col("db.status").equalTo(1)  // 上架状态
                    .and(col("es.id").isNull()
                        .or(col("db_name").notEqual(col("es_name")))
                        .or(col("db_price").notEqual(col("es_price"))))
            );

        // 保存不一致记录
        result.write()
            .mode(SaveMode.Overwrite)
            .parquet("/data/reconcile/inconsistent_" + today());

        // 统计
        long inconsistentCount = result.count();
        metrics.gauge("reconcile.full.inconsistent", inconsistentCount);
    }
}
```

---

## 四、数据修复策略

### 4.1 修复优先级

```
优先级定义：

P0（立即修复）：
- 价格不一致（影响交易）
- 库存不一致（影响下单）
- 状态不一致（上架/下架）

P1（1小时内修复）：
- 商品名称不一致
- 分类信息不一致
- 规格信息不一致

P2（24小时内修复）：
- 商品描述不一致
- 图片信息不一致
- 标签信息不一致

P3（按计划修复）：
- 历史商品数据
- 统计类数据
```

### 4.2 自动修复实现

```java
@Component
public class DataRepairService {

    // 修复单个商品
    public void repairProduct(Long productId, Set<String> targets) {
        Product dbProduct = productDao.selectById(productId);

        if (targets.contains("REDIS")) {
            repairRedis(productId, dbProduct);
        }

        if (targets.contains("ES")) {
            repairEs(productId, dbProduct);
        }

        if (targets.contains("LOCAL_CACHE")) {
            repairLocalCache(productId, dbProduct);
        }

        log.info("Product repaired: productId={}, targets={}", productId, targets);
    }

    private void repairRedis(Long productId, Product dbProduct) {
        if (dbProduct != null) {
            redisTemplate.opsForValue().set(
                "product:" + productId,
                dbProduct,
                5, TimeUnit.MINUTES);
        } else {
            redisTemplate.delete("product:" + productId);
        }
    }

    private void repairEs(Long productId, Product dbProduct) {
        if (dbProduct != null && dbProduct.getStatus() == ProductStatus.ON_SHELF) {
            esClient.index("product", productId.toString(), dbProduct);
        } else {
            esClient.delete("product", productId.toString());
        }
    }

    private void repairLocalCache(Long productId, Product dbProduct) {
        // 发送广播消息，通知所有机器刷新本地缓存
        CacheRefreshMessage message = new CacheRefreshMessage();
        message.setProductId(productId);
        message.setAction(dbProduct != null ? "REFRESH" : "INVALIDATE");
        mqProducer.sendBroadcast("local_cache_refresh", message);
    }
}
```

### 4.3 批量修复工具

```java
@RestController
@RequestMapping("/admin/repair")
public class DataRepairController {

    // 按商家修复
    @PostMapping("/byMerchant/{merchantId}")
    public Result repairByMerchant(@PathVariable Long merchantId) {
        List<Long> productIds = productDao.selectIdsByMerchantId(merchantId);

        // 异步执行修复
        asyncRepairService.repair(productIds);

        return Result.success("已提交修复任务，共 " + productIds.size() + " 个商品");
    }

    // 按时间范围修复
    @PostMapping("/byTimeRange")
    public Result repairByTimeRange(
            @RequestParam String startTime,
            @RequestParam String endTime) {
        List<Long> productIds = productDao.selectIdsByTimeRange(
            DateUtils.parse(startTime),
            DateUtils.parse(endTime));

        asyncRepairService.repair(productIds);

        return Result.success("已提交修复任务，共 " + productIds.size() + " 个商品");
    }

    // ES全量重建
    @PostMapping("/rebuildEs")
    public Result rebuildEs() {
        // 创建新索引
        String newIndex = "product_" + System.currentTimeMillis();
        esClient.createIndex(newIndex, getIndexMapping());

        // 异步全量写入
        asyncRepairService.rebuildEsIndex(newIndex);

        return Result.success("已启动ES索引重建任务");
    }
}
```

---

## 五、监控与告警

### 5.1 一致性监控指标

```java
// 监控指标定义
public class ConsistencyMetrics {

    // 同步延迟（从DB变更到各系统同步完成）
    private Histogram syncLatency = Histogram.build()
        .name("data_sync_latency_seconds")
        .labelNames("target")  // REDIS, ES, LOCAL_CACHE
        .help("Data sync latency in seconds")
        .register();

    // 不一致数量
    private Gauge inconsistentCount = Gauge.build()
        .name("data_inconsistent_count")
        .labelNames("source", "target")  // DB_REDIS, DB_ES
        .help("Number of inconsistent records")
        .register();

    // 修复数量
    private Counter repairCount = Counter.build()
        .name("data_repair_total")
        .labelNames("target", "type")  // AUTO, MANUAL
        .help("Total number of repaired records")
        .register();
}
```

### 5.2 告警规则

```yaml
# 告警规则配置
alerts:
  # 同步延迟告警
  - name: SyncLatencyHigh
    condition: data_sync_latency_seconds_p99 > 5
    level: P2
    message: "数据同步延迟过高，P99 > 5秒"

  # 不一致数量告警
  - name: InconsistentCountHigh
    condition: data_inconsistent_count > 1000
    level: P1
    message: "数据不一致数量过多，超过1000条"

  # 同步失败告警
  - name: SyncFailureRate
    condition: data_sync_failure_rate > 0.01
    level: P1
    message: "数据同步失败率过高，超过1%"

  # ES索引缺失告警
  - name: EsIndexMissing
    condition: es_index_count < db_online_count * 0.95
    level: P0
    message: "ES索引数量异常，与DB差异超过5%"
```

### 5.3 一致性大盘

```
┌──────────────────────────────────────────────────────────┐
│                   数据一致性监控大盘                       │
├──────────────────────────────────────────────────────────┤
│ 数据总量：                                                │
│ ├─ DB商品数：50亿                                        │
│ ├─ Redis缓存：5000万                                     │
│ ├─ ES索引：5亿                                           │
│                                                          │
│ 同步延迟（P99）：                                         │
│ ├─ DB → Redis：1.2秒                                     │
│ ├─ DB → ES：2.5秒                                        │
│ ├─ DB → 本地缓存：3.0秒                                   │
│                                                          │
│ 一致性状态：                                              │
│ ├─ DB-Redis 不一致：128条（0.0003%）✅                    │
│ ├─ DB-ES 不一致：356条（0.00007%）✅                      │
│                                                          │
│ 今日修复：                                                │
│ ├─ 自动修复：1,234条                                     │
│ ├─ 人工修复：12条                                        │
│                                                          │
│ 最近对账结果：                                            │
│ ├─ 增量对账（10:00）：不一致 45条，已修复                  │
│ ├─ 抽样对账（03:00）：不一致率 0.001%                     │
└──────────────────────────────────────────────────────────┘
```

---

## 六、实战案例

### 6.1 案例：ES集群故障恢复

**事故背景：**
- ES集群发生故障，部分分片丢失
- 恢复后发现约5%的商品索引缺失
- 用户搜索不到这些商品

**处理过程：**
```
10:00 - ES集群故障，触发告警
10:05 - 运维开始修复ES集群
10:30 - ES集群恢复，开始检查数据
10:35 - 发现索引缺失，约250万商品
10:40 - 启动紧急全量重建任务
12:00 - 索引重建完成50%
14:00 - 索引重建完成100%
14:10 - 对账确认数据一致
```

**改进措施：**
```java
// 增加ES健康检查
@Scheduled(fixedRate = 60000)
public void checkEsHealth() {
    // 检查索引数量
    long esCount = esClient.count("product");
    long dbCount = productDao.countOnline();

    double ratio = (double) esCount / dbCount;
    if (ratio < 0.95) {
        alertService.sendP0("ES索引数量异常，当前比例：" + ratio);
    }

    // 抽样检查数据一致性
    List<Long> sampleIds = productDao.randomSample(100);
    int inconsistentCount = 0;
    for (Long productId : sampleIds) {
        Product dbProduct = productDao.selectById(productId);
        Product esProduct = esClient.get(productId);
        if (!isEsConsistent(dbProduct, esProduct)) {
            inconsistentCount++;
        }
    }

    if (inconsistentCount > 5) {
        alertService.sendP1("ES数据一致性异常，抽样不一致率：" + inconsistentCount + "%");
    }
}
```

### 6.2 案例：Canal延迟导致缓存不一致

**问题现象：**
- 商家反馈修改价格后，用户看到的还是旧价格
- 排查发现Canal消费延迟达到5分钟

**原因分析：**
- MQ消费者处理慢，导致消息积压
- Canal服务内存不足，GC频繁

**解决方案：**
```java
// 1. 增加消费者并行度
@RocketMQMessageListener(
    topic = "product_data_sync",
    consumerGroup = "redis_sync_group",
    consumeThreadMax = 64)  // 增加消费线程

// 2. 增加Canal监控
@Scheduled(fixedRate = 10000)
public void monitorCanalDelay() {
    long binlogPosition = canalClient.getCurrentPosition();
    long mysqlPosition = mysqlClient.getCurrentBinlogPosition();

    long delay = mysqlPosition - binlogPosition;
    metrics.gauge("canal.delay", delay);

    if (delay > 10000) {  // 延迟超过1万条
        alertService.sendP1("Canal同步延迟过大：" + delay);
    }
}

// 3. 关键数据双写（绕过Canal）
@Transactional
public void updateProductPrice(Long productId, BigDecimal newPrice) {
    // 更新DB
    productDao.updatePrice(productId, newPrice);

    // 直接更新缓存（不依赖Canal）
    Product product = productDao.selectById(productId);
    redisTemplate.opsForValue().set("product:" + productId, product);

    // 发送同步消息（兜底）
    mqProducer.send("product_data_sync", buildSyncMessage(product));
}
```

---

## 七、最佳实践

### 7.1 数据一致性保障原则

```
1. 以DB为准
   - 任何不一致，以DB为最终真相
   - 修复逻辑简单，从DB重新同步

2. 最终一致性
   - 接受短时不一致（秒级）
   - 通过对账机制保证最终一致
   - 不追求强一致（成本太高）

3. 分层对账
   - 实时：同步结果追踪
   - 准实时：增量对账（小时级）
   - 离线：全量对账（天级）

4. 可观测
   - 同步延迟可监控
   - 不一致数量可统计
   - 修复过程可追溯
```

### 7.2 注意事项

```
1. 对账不能影响线上
   - 对账任务要限流
   - 大批量操作要分批
   - 高峰期暂停对账

2. 修复要谨慎
   - 先验证再修复
   - 保留修复前数据
   - 支持回滚

3. 避免循环同步
   - 同步消息要带版本号
   - 避免A→B→A的循环
```
